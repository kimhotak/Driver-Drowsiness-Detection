
## 전체 구조
이 프로젝트는 크게 세 단계로 구성됩니다:
1. **눈 영역 추출**: 웹캠/이미지에서 얼굴을 감지하고, 왼쪽/오른쪽 눈의 위치(영역)를 추출합니다.
2. **눈 감김 여부 판단**: 추출된 각 눈 영역에 대해 다양한 알고리즘(전통적 이미지 처리, 머신러닝, 딥러닝 등)으로 감김 여부를 판별합니다.
3. **졸음 판정 기준**: 감지된 눈이 일정 시간(예: 1초 이상) 연속으로 감긴 상태로 유지될 경우 졸음으로 판별합니다. 실시간 프레임 분석에서 감김 확률이 임계치(예: 0.8) 이상으로 지속되는 시간을 누적하여 판단합니다.

이 구조를 통해 눈 위치 추출과 감김 판단이 명확하게 분리되어 있으며, 여러 감지기(알고리즘)를 쉽게 교체하거나 비교할 수 있습니다.

# Eye Close Detection: 운전자 피로도 분석 데모

## 전체 구조
이 프로젝트는 크게 두 단계로 구성됩니다:
1. **눈 영역 추출**: 웹캠/이미지에서 얼굴을 감지하고, 왼쪽/오른쪽 눈의 위치(영역)를 추출합니다.
2. **눈 감김 여부 판단**: 추출된 각 눈 영역에 대해 다양한 알고리즘(전통적 이미지 처리, 머신러닝, 딥러닝 등)으로 감김 여부를 판별합니다.

이 구조를 통해 눈 위치 추출과 감김 판단이 명확하게 분리되어 있으며, 여러 감지기(알고리즘)를 쉽게 교체하거나 비교할 수 있습니다.

## 프로젝트 개요
운전자의 눈 개폐 상태를 실시간으로 분석하여 졸음·피로도를 판단하는 컴퓨터 비전 기반 데모 프로젝트입니다.
여러 감지기(OpenCV, 랜드마크, 머신러닝, 딥러닝, 적외선)를 직접 비교할 수 있도록 구성되어 있습니다.

## 주요 특징
- 다양한 감지기(백엔드)별 결과를 한 화면에서 비교 가능
- OpenCV 창 또는 Jupyter 노트북 기반 GUI 데모 제공
- 실시간 웹캠 영상 또는 이미지 파일 테스트 지원

## 파일 구조
- `eyeCloseDetection/` : 감지기별 구현 코드 (OpenCV, ML, DL, IR, 랜드마크)
- `eyeDetection/` : 눈 영역 추출 코드
- `Sample.ipynb` : 여러 감지기를 동시에 실행하여 결과를 시각화하는 Jupyter 데모
- `test_run.py` : 이미지 파일을 불러와 감지 결과를 출력하는 테스트 코드
- `test_sleep_detection.py` : 감지기별로 졸음 감지 로직을 실행하는 예제

## 사용 예시

### 1. 여러 감지기 결과를 한 번에 비교 (Jupyter 노트북)
- `Sample.ipynb`에서는 Point, OpenCV, ML 감지기를 동시에 실행하여 각 결과를 화면에 표시합니다.
- 웹캠 프레임을 받아 각 감지기의 `eye_close_detecte` 메서드를 호출하고, 확률을 화면에 출력합니다.

### 2. 단일 이미지 테스트 (test_run.py)
- 이미지 파일을 불러와서 감지기를 통해 감김 여부를 예측하고, 결과를 콘솔에 출력합니다.

### 3. 실시간 졸음 감지 (test_sleep_detection.py)
- 감지기별로 실시간 영상에서 졸음 감지 로직을 실행할 수 있습니다.

## 주의사항
- 본 프로젝트는 서버/REST API/배포용 라이브러리가 아니라, 로컬 데모 및 실험용 코드 중심입니다.
- GUI(영상 창, 노트북 등)로 결과를 직접 확인하는 방식이 주를 이룹니다.

## 팀
- 팀 4조(스마트팩토리): 김호탁(팀장), 김진현, 안승현, 윤선아, 박준규
